{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 7: Bagging and Boosting\n",
    "\n",
    "Only use the already imported library `numpy`, `matplotlib` and the Python standard library. For the evaluation you may also use scikit-learn (`sklearn`). Make sure that the dataset `titanic.csv` is in the same directory as the notebook.\n",
    "\n",
    "List your team members (name and immatriculation number) and indicate whether you are a B.Sc. Data Science or other group in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "\n",
    "Min Wang 3440557\n",
    "\n",
    "Sisi Miao 3377882\n",
    "    \n",
    "Dominik Sellenthin 2836308   \n",
    "    \n",
    "</h3>\n",
    "\n",
    "We are Master students.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 15)\n",
      "[ 0.   20.    7.05  0.    0.    1.    0.    0.    0.    0.    1.    1.\n",
      "  0.    0.    1.  ]\n"
     ]
    }
   ],
   "source": [
    "# You are allowed to use the numpy package and the DecisionTreeClassifier.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "def load_dataset(path):\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    df = pd.read_csv('titanic.csv')\n",
    "    # The feature engineering mostly follows the notebook by Manav Segal: https://www.kaggle.com/startupsci/titanic-data-science-solutions\n",
    "    # From the Name attribute we can extract titles, which gives insight about the social status/age/gender of the passenger.\n",
    "    df['Title'] = df['Name'].str.extract(' ([a-zA-Z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    # We map the Title attribute to a one-hot encoding.\n",
    "    df = df.join(pd.get_dummies(df['Title'], prefix='Title'))\n",
    "\n",
    "    # We map the Sex attribute to a numeric representation.\n",
    "    df['Sex'] = df['Sex'].map({'female': 1, 'male': 0}).astype(int)\n",
    "\n",
    "    # We one-hot encode Pclass.\n",
    "    df = df.join(pd.get_dummies(df['Pclass'], prefix='Pclass'))\n",
    "\n",
    "    # Based on the number of sibling-spouses in SibSp and parents-childern in Parch, \n",
    "    # we can determine whether a passenger was on board alone.\n",
    "    df['IsAlone'] = ((df['SibSp'] + df['Parch'] + 1) == 1).astype(int)\n",
    "\n",
    "    # We remove all attributes that do not seem relevant to the prediction, or are already encoded in another attribute.\n",
    "    df = df.drop(['PassengerId', 'Name', 'Title', 'Ticket', 'Cabin', 'Parch', 'SibSp'], axis=1)\n",
    "\n",
    "    # For remaining features, we have to separate train and test, \n",
    "    # as we will impute missing data based on statistics in the training data.\n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=2020)\n",
    "    # For Embarked, we set all missing values to the most frequent port and then one-hot encode the attribute.\n",
    "    def impute_embarked():    \n",
    "        freq_port = df_train['Embarked'].dropna().mode()[0]\n",
    "        output = []\n",
    "        for df in (df_train, df_test):\n",
    "            df = df.join(pd.get_dummies(df['Embarked'].fillna(freq_port), prefix='Embarked'))\n",
    "            df = df.drop('Embarked', axis=1)\n",
    "            output.append(df)\n",
    "        return output\n",
    "\n",
    "    df_train, df_test = impute_embarked()\n",
    "\n",
    "    # For Age, we set missing values to the median dependent on the pair of Sex and Pclass.\n",
    "    guess_ages = np.zeros((2, 3))\n",
    "    for df in (df_train, df_test):\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                guess_ages[i, j] = df[(df['Sex'] == i) & (df['Pclass'] == j+1)]['Age'].dropna().median()\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                df.loc[(df['Age'].isnull()) & (df['Sex'] == i) & (df['Pclass'] == j+1), 'Age'] = guess_ages[i, j]\n",
    "        df['Age'] = df['Age'].astype(int)\n",
    "\n",
    "    df_train = df_train.drop(['Pclass'], axis=1)\n",
    "    df_test = df_test.drop(['Pclass'], axis=1)\n",
    "\n",
    "    X_train = df_train.values[:, 1:]\n",
    "    X_test = df_test.values[:, 1:]\n",
    "    y_train = df_train.values[:, 0]\n",
    "    y_test = df_test.values[:, 0]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "X_train, X_test, y_train, y_test = load_dataset('titanic.csv')\n",
    "\n",
    "\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_train[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n"
     ]
    }
   ],
   "source": [
    "#print(X_train.shape[0])\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Titanic dataset and a description can be found at [Kaggle](https://www.kaggle.com/c/titanic/data). The feature engineering mostly follows the work by [Manav Segal](https://www.kaggle.com/startupsci/titanic-data-science-solutions). \n",
    "\n",
    "The prepared dataset contains the following attributes:\n",
    "- Sex: binary (0 = Male, 1 = Female)\n",
    "- Age: integer\n",
    "- Fare: float\n",
    "- Title_{Master, Miss, Mr, Mrs, Rare}: title of passenger (extracted from name), binary, one-hot encoding of categorical variable Title\n",
    "- Pclass_{1, 2, 3}: ticket class corresponds to socio-economic status (1 = upper class, 2 = middle class, 3 = lower class), binary, one-hot encoding of categorical variable Pclass\n",
    "- IsAlone: whether the passenger has no siblings/spouses/parents/children on board, binary\n",
    "- Embarked_{C, Q, S}: port at which passenger embarked (C = Cherbourg, Q = Queenstown, S = Southampton), binary, one-hot encoding of categorical variable Embarked\n",
    "\n",
    "The classification target is:\n",
    "- Survived: binary\n",
    "\n",
    "Data is split into train-test with a 80-20 ratio yielding 712 training and 179 test samples. Train and test data is stored in the variables `(X_train, y_train)` and `(X_test, y_test)` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Random Forest\n",
    "\n",
    "In this task, you will implement a random forest classifier using the scikit-learn implementation of the decision tree. \n",
    "\n",
    "Use bootstrap sampling and sample 20% of the original data set for each tree. Randomly select 6 attributes/columns for each trained tree. The prediction of each tree should be weighted equally in the majority vote. Use the already imported class `DecisionTreeClassifier` for your decision trees. You can find the decision tree documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). You may use either the default parameters or experiment with different settings.\n",
    "\n",
    "You will evaluate your model on the test data using scikit-learn with the methods shown in the lecture ([precision, recall, F1-score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support), [confusion matrices](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion%20matrix#sklearn.metrics.confusion_matrix), ...). Try out different number of trees and compare the performance w.r.t. this parameter. Feel free to import any functions you need from scikit-learn for this purpose. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestClassifier(object):\n",
    "    def __init__(self, X,y, number_of_trees, max_features, max_samples=0.2, depth=None, min_samples_leaf=2):\n",
    "        # Add your code, such as initialization of trees here.\n",
    "        np.random.seed(12)\n",
    "        self.X, self.y=X,y\n",
    "        \n",
    "        self.max_features = max_features\n",
    "\n",
    "        self.number_of_trees = number_of_trees\n",
    "        self.max_samples, self.depth, self.min_samples_leaf  = max_samples, depth, min_samples_leaf\n",
    "        \n",
    "        self.trees = [self.create_tree() for i in range(self.number_of_trees)]\n",
    "        \n",
    "    def create_tree(self):\n",
    "        # Implement your training here.\n",
    " \n",
    " \n",
    "        return DecisionTreeClassifier(max_features=self.max_features,max_depth = self.depth, min_samples_leaf=self.min_samples_leaf)\n",
    "    \n",
    "    def fit (self, X, y):\n",
    "        self.max_samples=int(X_train.shape[0]*0.2)\n",
    "        idxs = np.random.permutation(len(self.y))[:self.max_samples]\n",
    "        return [t.fit(X[idxs], y[idxs]) for t in self.trees]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Implement your prediction here.\n",
    "        '''for t in self.trees:\n",
    "            pridiction=t.predict(X) \n",
    "            print('pridiction',pridiction)\n",
    "        '''\n",
    "        pred=np.mean([t.predict(X) for t in self.trees], axis=0)\n",
    "        pred=np.where(pred > 0.5,1,0)\n",
    "        #print('pred',pred)\n",
    "        #print('pred, after',pred)\n",
    "        return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix [[99  6]\n",
      " [35 39]]\n",
      "precision_recall_fscore_support (0.8027363184079602, 0.7349420849420849, 0.7419570338595689, None)\n",
      "roc_auc 0.7349420849420849\n"
     ]
    }
   ],
   "source": [
    "# Implement your training and evaluation here.\n",
    "\n",
    "rf = RandomForestClassifier(X_train,y_train, number_of_trees=10,max_features=6)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "#evaluate\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#print('y_test',y_test, 'y_pred',y_pred)\n",
    "print('confusion_matrix',confusion_matrix(y_test, y_pred))\n",
    "print('precision_recall_fscore_support',precision_recall_fscore_support(y_test, y_pred, average='macro'))\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "print('roc_auc',roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "   rf = RandomForestClassifier(X_train,y_train,max_features=6,number_of_trees=estimator)\n",
    "   rf.fit(X_train, y_train)\n",
    "   train_pred = rf.predict(X_train)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   train_results.append(roc_auc)\n",
    "   y_pred = rf.predict(X_test)\n",
    "   false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "   roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "   test_results.append(roc_auc)\n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for our data and fix other parameters, we can stop at 16 trees for test data as increasing the number of trees decreases the test performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Interpreting Random Forests\n",
    "\n",
    "Implement the mean decrease of accuracy for the [sklearn.ensemble.RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) `forest` to analyse learned attribute importances. Use the test set `X_test` and `y_test` as out-of-bag-samples. Permute the values of the assessed attribute by randomly shuffling the corresponding column. Plot the results to compare the importance of each feature. Discuss your results (are any importance values surprising, do the results make sense in the context of the task, ...).\n",
    "\n",
    "Note: We have already trained the classifier and stored it in the variable `forest`. You only need to implement MDA and the plots for your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: [0.78070175 0.75384615]\n",
      "Recall: [0.84761905 0.66216216]\n",
      "F1-score: [0.81278539 0.70503597]\n"
     ]
    }
   ],
   "source": [
    "def create_forest():\n",
    "    import sklearn.ensemble\n",
    "    import sklearn.metrics\n",
    "    forest = sklearn.ensemble.RandomForestClassifier(8)\n",
    "    forest.fit(X_train, y_train)\n",
    "    prec, rec, f1, _ = sklearn.metrics.precision_recall_fscore_support(y_test, forest.predict(X_test))\n",
    "    print('Precision:', prec)\n",
    "    print('Recall:', rec)\n",
    "    print('F1-score:', f1)\n",
    "    return forest\n",
    "\n",
    "forest = create_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original accuracy : 0.770949720670391\n",
      "Features sorted by their score:\n",
      "[(0.1173, 'Title_Mr'), (0.0782, 'Sex'), (0.0335, 'Pclass_3'), (0.0279, 'Title_Miss'), (0.0223, 'Embarked_Q'), (0.0168, 'Title_Master'), (0.0168, 'Pclass_2'), (0.0168, 'Age'), (0.0112, 'Fare'), (0.0112, 'Embarked_S'), (0.0, 'Title_Rare'), (0.0, 'Title_Mrs'), (0.0, 'Embarked_C'), (-0.0056, 'Pclass_1'), (-0.0279, 'IsAlone')]\n"
     ]
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "names=['Sex','Age','Fare',\n",
    "'Title_Master', 'Title_Miss', 'Title_Mr', 'Title_Mrs', 'Title_Rare',\n",
    "'Pclass_1', 'Pclass_2', 'Pclass_3',\n",
    "'IsAlone','Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "\n",
    "acc = accuracy_score(y_test, forest.predict(X_test))\n",
    "print('Original accuracy :',acc)\n",
    "scores = defaultdict(list)\n",
    "for i in range(X_train.shape[1]):\n",
    "    X_t = X_test.copy()\n",
    "    np.random.shuffle(X_t[:, i])\n",
    "    shuff_acc = accuracy_score(y_test, forest.predict(X_t))\n",
    "    scores[names[i]].append(acc-shuff_acc)\n",
    "print (\"Features sorted by their score:\")\n",
    "print (sorted([(round(np.mean(score), 4), feat) for\n",
    "              feat, score in scores.items()], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the namesList for features (We assume the list is correct.)\n",
    "After Permuting, the accuracy Decreacy scores are showed as above.\n",
    "We noticed that 'Title_Mr', 'Sex', 'Pclass_3','Title_Miss' are more important than other features. \n",
    "A negative value in the importance means that the random permutation of a feature worked better than the original values. This implies that the feature has no role in the prediction and is therefore not important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Discrete AdaBoost with Decision Stumps\n",
    " \n",
    "*For all students other than B.Sc. Data Science.*  \n",
    "\n",
    "In this task, you will implement the discrete AdaBoost algorithm using decision stumps as weak learners. Your training will run until either `n_learners` weak learners have been added or a perfect accuracy on the training data set is achieved. Use the function `initialize_decision_stumps` to create decision stumps, which you can train on your weighted data using `fit` and predict using `predict`. The decision stumps are instances of the class [sklearn.tree.DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "In addition, you will evaluate your model on the test data (`X_test`, `y_test`) using scikit-learn with the methods shown in the lecture (precision, recall, F1-score, confusion matrices, ...). Feel free to import any functions you need from scikit-learn for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_decision_stump():\n",
    "    stump = DecisionTreeClassifier(criterion='entropy', max_depth=1)\n",
    "    return stump\n",
    "\n",
    "\n",
    "class AdaBoostClassifier(object):\n",
    "    def __init__(self, n_learners=50):\n",
    "        self.n_learners = n_learners\n",
    "        # Add any initialization you need here.\n",
    "       \n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Implement your solution here.\n",
    "        weights = np.full(y.shape,1/len(y)) # init weights for all samples in dataset-> w = 1/N\n",
    "\n",
    "\n",
    "        # for storing stumps\n",
    "        self.clfs=[]\n",
    "        \n",
    "        \n",
    "        for _ in range(self.n_learners):#build up desicion stumps\n",
    "            min_error=float('inf')\n",
    "            clf = initialize_decision_stump() \n",
    "                \n",
    "            clf = clf.fit(X,y,sample_weight=weights) \n",
    "            # Append the single weak classifiers to a list which is later on used to make the weighted decision\n",
    "\n",
    "            predictions = clf.predict(X)\n",
    "\n",
    "            \n",
    "            # Calculate the weighted misclassification rate \n",
    "            wrong_flag=np.where(y!=predictions,1,0)\n",
    "            err = np.sum(weights*wrong_flag)/np.sum(weights)\n",
    "\n",
    "\n",
    "            # Calculate the alpha value(amount of say) for a stump\n",
    "            clf.alpha = 0.5*np.log((1-err)/err+1e-10) #in case of error=0\n",
    "\n",
    "            \n",
    "            # Update the weights wi --> These updated weights are used in the sample_weight parameter for the training of the next decision stump. \n",
    "            weights *= np.exp(-clf.alpha*y*predictions)#1 if y=pred; -1 if y!=pred\n",
    "            weights /= np.sum(weights)#normaliaztion \n",
    "\n",
    "            self.clfs.append(clf)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def predict(self, X, y):\n",
    "        # Implement your solution here.\n",
    "        \n",
    "        # With each model in the model list, make a prediction \n",
    "        clf_preds=[clf.alpha*clf.predict(X) for clf in self.clfs]#Individual weighted prediction for all models (shape:n_learners*numberOfsamples)\n",
    "    \n",
    "        y_pred=np.sign(np.sum(clf_preds,axis=0))#overall prediction for all samples(shape:1*numberOfsamples)\n",
    "        \n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test_modified [ 1 -1  1  1 -1 -1 -1  1 -1  1  1 -1 -1  1  1  1  1 -1 -1 -1  1  1 -1  1\n",
      " -1  1 -1  1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1  1  1 -1 -1 -1 -1  1  1 -1\n",
      " -1 -1 -1 -1  1 -1  1 -1  1  1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1  1  1\n",
      " -1  1  1 -1 -1 -1  1  1 -1  1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1 -1 -1 -1\n",
      " -1  1 -1 -1  1  1 -1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1  1\n",
      " -1 -1 -1 -1  1  1  1  1  1  1 -1 -1  1 -1 -1 -1  1  1  1  1  1  1 -1 -1\n",
      "  1 -1 -1 -1  1 -1 -1  1  1 -1 -1  1  1 -1  1 -1  1 -1  1  1  1  1 -1 -1\n",
      "  1 -1  1 -1 -1  1  1 -1 -1 -1  1] y_pred [ 1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1.\n",
      "  1. -1. -1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1. -1. -1.  1.  1.\n",
      "  1. -1.  1. -1. -1.  1. -1.  1. -1. -1.  1. -1. -1. -1. -1. -1.  1.  1.\n",
      " -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.  1.  1.\n",
      " -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.  1. -1.\n",
      "  1.  1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1. -1.  1.  1. -1. -1. -1.\n",
      " -1.  1. -1.  1. -1. -1. -1. -1. -1.  1. -1.  1.  1. -1.  1.  1.  1.  1.\n",
      " -1. -1. -1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1. -1.  1. -1. -1. -1.\n",
      "  1. -1. -1.  1.  1. -1.  1. -1.  1. -1. -1.  1. -1. -1. -1. -1.  1.]\n",
      "roc_auc 0.7458172458172458\n"
     ]
    }
   ],
   "source": [
    "# Implement your training and evaluation here. You may reuse the code from Task 1.\n",
    "#class1 -> +1, class 2 -> -1\n",
    "y_train_modified=np.where(y_train==0,-1,1)\n",
    "y_test_modified=np.where(y_test==0,-1,1)\n",
    "\n",
    "#training\n",
    "classifier = AdaBoostClassifier(n_learners=50)\n",
    "classifier.fit(X_train, y_train_modified)\n",
    "y_pred = classifier.predict(X_test,y_test_modified)\n",
    "\n",
    "\n",
    "#evaluate\n",
    "print('y_test_modified',y_test_modified, 'y_pred',y_pred)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_modified, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "print('roc_auc',roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluation\n",
    "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200]\n",
    "\n",
    "train_results = []\n",
    "test_results = []\n",
    "for estimator in n_estimators:\n",
    "    classifier = AdaBoostClassifier(n_learners=estimator)\n",
    "    classifier.fit(X_train, y_train_modified)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test,y_test_modified)\n",
    "    train_pred = classifier.predict(X_train,y_test_modified)\n",
    "    \n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train_modified, train_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    train_results.append(roc_auc)\n",
    "\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_modified, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    test_results.append(roc_auc)\n",
    "    \n",
    "from matplotlib.legend_handler import HandlerLine2D\n",
    "line1, = plt.plot(n_estimators, train_results, 'b', label='Train AUC')\n",
    "line2, = plt.plot(n_estimators, test_results, 'r', label='Test AUC')\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel('AUC score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we increase the number of weak learners the auc score increases for traning data; while for the test data, the curve is a little bit strange and we don't know how to explain it and hope we can get some tutoring about it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
