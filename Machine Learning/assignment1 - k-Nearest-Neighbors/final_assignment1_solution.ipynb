{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: k-nearest neighbors\n",
    "\n",
    "Only use the already imported libraries `numpy` and `matplotlib.pyplot` for the assignment. Do not import any other library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "\n",
    "Min Wang 3440557\n",
    "\n",
    "Stoyan Dimitrov 3460278\n",
    "\n",
    "Dominik Sellenthin 2836308</h3>\n",
    "\n",
    "<h5>Note ï¼š</h5>  We wish to present task1 and task2. If the solution of task3 is correct, we can also present task3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages and dataset. Do not modify.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_iris_dataset():\n",
    "    from sklearn import datasets\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "    \n",
    "X, y = load_iris_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Visualization and Preprocessing\n",
    "\n",
    "1) Explain the content of the dataset in few words. What are the input features? What is the classification target? Check out: [https://en.wikipedia.org/wiki/Iris_flower_data_set](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==> *Write your response here* (double klick here to edit)\n",
    "Input features:        four numeric features: the sepal length, the sepal width, the petal length and the petal width, type: float\n",
    "Classification target: three nominal class (three species of Iris (Iris setosa, Iris virginica and Iris versicolor)), labels are int64:0,1,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Compute and print the following statistics about the dataset:\n",
    "  - Number of samples\n",
    "  - Number of samples per class\n",
    "  - Mean and standard deviation for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is: 150\n",
      "Number of samples class 0 is: 50\n",
      "Number of samples class 1 is: 50\n",
      "Number of samples class 2 is: 50\n",
      "Means of each feature are:  [5.843 3.057 3.758 1.199]\n",
      "Standard deviation of each feature are:  [0.825 0.434 1.759 0.76 ]\n"
     ]
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "num_sample = X.shape[0]               # Number of samples\n",
    "num_sample_per_class_0 = np.sum(y==0) # Number of samples per class\n",
    "num_sample_per_class_1 = np.sum(y==1)\n",
    "num_sample_per_class_2 = np.sum(y==2)\n",
    "mean_features = np.mean(X, axis=0)    # Mean and standard deviation for each input feature\n",
    "st_deviations = np.std(X, axis=0)\n",
    "\n",
    "print(\"Number of samples is: %d\" % num_sample)\n",
    "print(\"Number of samples class 0 is: %d\" % num_sample_per_class_0)\n",
    "print(\"Number of samples class 1 is: %d\" % num_sample_per_class_1)\n",
    "print(\"Number of samples class 2 is: %d\" % num_sample_per_class_2)\n",
    "print(\"Means of each feature are: \", np.around(mean_features, 3))\n",
    "print(\"Standard deviation of each feature are: \", np.around(st_deviations, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Visualize the variables Sepal length and Petal length in a scatter plot (Sepal length on the x-axis, petal length on the y-axis). Color each point of the plot according to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "sepal_lengths = [X[y==0, 0], X[y==1, 0], X[y==2, 0]]\n",
    "petal_lengths = [X[y==0, 2], X[y==1, 2], X[y==2, 2]]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot()\n",
    "a1 = ax.scatter(sepal_lengths[0], petal_lengths[0], c='green')\n",
    "a2 = ax.scatter(sepal_lengths[1], petal_lengths[1], c='blue')\n",
    "a3 = ax.scatter(sepal_lengths[2], petal_lengths[2], c='red')\n",
    "plt.xlabel('Sepal length (cm)')\n",
    "plt.ylabel('Petal length (cm)')\n",
    "sp_labels = ['class 0', 'class 1', 'class 2']\n",
    "plt.legend(handles=[a1, a2, a3],labels=sp_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Split the dataset randomly into training and test data. 70% of data should be used for training and 30% should be used for testing. Implement the function `train_test_split`. Do not modify the interface of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y):\n",
    "    \"\"\"\n",
    "    Returns X_train, X_test, y_train, y_test, \n",
    "        where X_train and X_test are the input features of the training and test set,\n",
    "        and y_train and y_test are the class labels of the training and test set.\n",
    "    \"\"\"\n",
    "    # Implement your solution here.\n",
    "    test_split = 0.3                \n",
    "    sample_size = X.shape[0]\n",
    "    test_size = int(sample_size * test_split)\n",
    "\n",
    "    indices = np.arange(sample_size)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    X_test = X[indices[:test_size], :]\n",
    "    y_test = y[indices[:test_size]]\n",
    "    X_train = X[indices[test_size:], :]\n",
    "    y_train = y[indices[test_size:]]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "np.random.seed(46)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "assert (X_train.shape[0] + X_test.shape[0]) == X.shape[0]\n",
    "assert (y_train.shape[0] + y_test.shape[0]) == y.shape[0]\n",
    "assert X_train.shape[1] == X_test.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) kNN uses a distance measure to identify close neighbors. If the input features are not of the same scale, the distance is not as meaningful, which can negatively impact classification performance. Perform min-max scaling (i.e. scale the values of the input features in such a way that their range is from 0 to 1) on the training and test data. Remember that you should only use information from the training data to perform the scaling on both data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.4 2.  1.  0.1]]\n"
     ]
    }
   ],
   "source": [
    "# Implement your solution here\n",
    "X_train_min = np.amin(X_train, axis=0).reshape(1, -1)\n",
    "X_train_max = np.amax(X_train, axis=0).reshape(1, -1)\n",
    "print(X_train_min)\n",
    "X_train = (X_train - X_train_min) / (X_train_max - X_train_min)\n",
    "X_test = (X_test - X_train_min) / (X_train_max - X_train_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: k-nearest neighbors\n",
    "\n",
    "**For B.Sc. Data Science:**  \n",
    "Implement the kNN algorithm with uniform weighting and arbitrary `k`. Fill out the `predict` method of class `KNearestNeighborsClassifier`. \n",
    "\n",
    "You can ignore the optional parameter `distance_metric`, which is provided as a field in the kNN class.\n",
    "\n",
    "**For everyone else:**  \n",
    "Implement the kNN algorithm with distance-based weighting and arbitrary `k`.\n",
    "Fill out the `predict` method of class `KNearestNeighborsClassifier`.\n",
    "\n",
    "The parameter `distance_metric` will either contain the string `uniform` or a function. If the value is `uniform`, the classifier should use uniform weighting. If the value is a function, the classifier should use the function as distance metric and perform distance-weighted classification. An example distance metric is provided with `euclidean_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors(object):\n",
    "    def __init__(self, k, distance_metric='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        This functions saves the training data to be used during the prediction.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns a vector of shape (n,) if X has shape (n,k).\n",
    "        \"\"\"\n",
    "        # Implement your solution here.\n",
    "        dataset_size = self.X.shape[0]\n",
    "        y_pred = np.ones(X.shape[0])\n",
    "        for test_i in range(X.shape[0]):\n",
    "            distance = euclidean_distance(np.tile(X[test_i, :].reshape(1,-1), (dataset_size, 1)), self.X)\n",
    "            sort_distance_index = distance.argsort()\n",
    "            \n",
    "            class_counted = {}\n",
    "            \n",
    "            w_i = 1\n",
    "            for i in range(self.k):\n",
    "                if(self.distance_metric == 'euclidean'):\n",
    "                    if distance[sort_distance_index[i]] == 0:\n",
    "                        w_i = 9999.9\n",
    "                    w_i = 1.0 / distance[sort_distance_index[i]]\n",
    "                vote_i_label = self.y[sort_distance_index[i]]\n",
    "                class_counted[vote_i_label] = class_counted.get(vote_i_label, 0) + w_i  # weight\n",
    "            \n",
    "            sort_class_counted = sorted(class_counted.items(), key=lambda f:f[1], reverse=True)\n",
    "               \n",
    "            y_pred[test_i] = sort_class_counted[0][0]\n",
    "            \n",
    "            \n",
    "        return y_pred\n",
    "\n",
    "    \n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"\n",
    "    Given vectors x1 and x2 with shape (n,) returns distance between vectors as float.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum((x1 - x2)*(x1 - x2), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Evaluation\n",
    "\n",
    "1) Implement functions to compute precision, recall and F1-score. `y_pred` and `y_true` are the vectors of predicted and true class labels respectively with shape `(n,)`, where `n` is the number of samples. Each function should return a float containing the corresponding score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i just don't want to change the structure...\n",
    "def precision(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    # average precision for all class\n",
    "    y_labels = [0, 1, 2]\n",
    "    pre_sum = 0\n",
    "    for y_label_i in y_labels:\n",
    "        tp_ = ((y_pred==y_label_i)&(y_true==y_label_i)).sum()\n",
    "        fp_ = ((y_pred==y_label_i)&(y_true!=y_label_i)).sum()\n",
    "        fn_ = ((y_pred!=y_label_i)&(y_true==y_label_i)).sum()\n",
    "        tn_ = ((y_pred!=y_label_i)&(y_true!=y_label_i)).sum()\n",
    "        pre_sum += (tp_ / (tp_ + fp_))\n",
    "    return pre_sum / len(y_labels)\n",
    "        \n",
    "def recall(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    # average precision for all class\n",
    "    y_labels = [0, 1, 2]\n",
    "    rec_sum = 0\n",
    "    for y_label_i in y_labels:\n",
    "        tp_ = ((y_pred==y_label_i)&(y_true==y_label_i)).sum()\n",
    "        fp_ = ((y_pred==y_label_i)&(y_true!=y_label_i)).sum()\n",
    "        fn_ = ((y_pred!=y_label_i)&(y_true==y_label_i)).sum()\n",
    "        tn_ = ((y_pred!=y_label_i)&(y_true!=y_label_i)).sum()\n",
    "        rec_sum += (tp_ / (tp_ + fn_))\n",
    "    return rec_sum / len(y_labels)\n",
    "\n",
    "def f1score(y_pred, y_true):\n",
    "    # Implement your solution here.\n",
    "    # average precision for all class\n",
    "    y_labels = [0, 1, 2]\n",
    "    f_sum = 0\n",
    "    for y_label_i in y_labels:\n",
    "        tp_ = ((y_pred==y_label_i)&(y_true==y_label_i)).sum()\n",
    "        fp_ = ((y_pred==y_label_i)&(y_true!=y_label_i)).sum()\n",
    "        fn_ = ((y_pred!=y_label_i)&(y_true==y_label_i)).sum()\n",
    "        tn_ = ((y_pred!=y_label_i)&(y_true!=y_label_i)).sum()\n",
    "        f_sum += 2*tp_ / (2*tp_ + fn_ + fp_ )\n",
    "    return f_sum / len(y_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Evaluate the performance of kNN with uniform weighting on the Iris dataset for `k=1,3,5`. Train each of the `3` classifiers on the training data from Task 1. Perform the predictions on both the training and test data. Then compute precision, recall, and F1-score for each model and for both training and test data. Print all scores per model. What do you observe?\n",
    "\n",
    "**For all students other than B.Sc. Data Science:** \n",
    "Evaluate the kNN classifier with Euclidean distance-weighting. Compare the performance to uniform-weighting. How does the performance change compared to uniform weighting for each `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform_k_1_results: precision:0.907692, recall:0.907692, f1_score:0.904762\n",
      "uniform_k_3_results: precision:0.907692, recall:0.907692, f1_score:0.904762\n",
      "uniform_k_5_results: precision:0.880952, recall:0.882051, f1_score:0.880800\n",
      "euclidean_k_1_results: precision:0.907692, recall:0.907692, f1_score:0.904762\n",
      "euclidean_k_3_results: precision:0.907692, recall:0.907692, f1_score:0.904762\n",
      "euclidean_k_5_results: precision:0.880952, recall:0.882051, f1_score:0.880800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:31: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Implement your solution here.\n",
    "def evaluation(data, k=1, w='uniform'):\n",
    "    X_train, X_test, y_train, y_test = data\n",
    "    clf = KNearestNeighbors(k=k, distance_metric=w)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision_value = precision(y_pred, y_test)\n",
    "    recall_value = recall(y_pred, y_test)\n",
    "    f1_value = f1score(y_pred, y_test)\n",
    "    \n",
    "    return [precision_value, recall_value, f1_value]\n",
    "    \n",
    "data = X_train, X_test, y_train, y_test\n",
    "# Uniform --- k = 1\n",
    "uniform_k_1_results = evaluation(data, k=1, w='uniform')\n",
    "print(\"uniform_k_1_results: precision:%f, recall:%f, f1_score:%f\" % \n",
    "      (uniform_k_1_results[0], uniform_k_1_results[1], uniform_k_1_results[2]))\n",
    "\n",
    "# Uniform --- k = 3\n",
    "uniform_k_3_results = evaluation(data, k=3, w='uniform')\n",
    "print(\"uniform_k_3_results: precision:%f, recall:%f, f1_score:%f\" % \n",
    "      (uniform_k_3_results[0], uniform_k_3_results[1], uniform_k_3_results[2]))\n",
    "\n",
    "# Uniform --- k = 5\n",
    "uniform_k_5_results = evaluation(data, k=5, w='uniform')\n",
    "print(\"uniform_k_5_results: precision:%f, recall:%f, f1_score:%f\" % \n",
    "      (uniform_k_5_results[0], uniform_k_5_results[1], uniform_k_5_results[2]))\n",
    "\n",
    "# Euclidean --- k = 1\n",
    "euclidean_k_1_results = evaluation(data, k=1, w='euclidean')\n",
    "print(\"euclidean_k_1_results: precision:%f, recall:%f, f1_score:%f\" % \n",
    "      (euclidean_k_1_results[0], euclidean_k_1_results[1], euclidean_k_1_results[2]))\n",
    "\n",
    "# Euclidean --- k = 3\n",
    "euclidean_k_3_results = evaluation(data, k=3, w='euclidean')\n",
    "print(\"euclidean_k_3_results: precision:%f, recall:%f, f1_score:%f\" % \n",
    "      (euclidean_k_3_results[0], euclidean_k_3_results[1], euclidean_k_3_results[2]))\n",
    "\n",
    "# Euclidean --- k = 5\n",
    "euclidean_k_5_results = evaluation(data, k=5, w='euclidean')\n",
    "print(\"euclidean_k_5_results: precision:%f, recall:%f, f1_score:%f\" % \n",
    "      (euclidean_k_5_results[0], euclidean_k_5_results[1], euclidean_k_5_results[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=5 seems to be too large for this task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Explain why kNN with `k=1` achieves perfect results on the training data. Why is it not the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=1 tested on the training data maps the test example exactly on themselves, achieving perfect score. But on new samples k=1 won't generalize well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
